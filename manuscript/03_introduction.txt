# Introduction

## Industrie 4.0, Industrie du Futur, Smart XX : véritables enjeux
En lançant l’initiative Industrie 4.0 en 2012, l’Allemagne a déclenché un réflexe épidermique hexagonal, d’abord baptisé Usine du Futur (2012), puis Industrie du Futur (2015). L’Europe, qui avait inventé le terme Smart Manufacturing , semblait réagir avec un train de retard et en ordre dispersé à l’esprit Smart développé par les USA en pleine crise financière : smart manufacturing, smart grid, smart water, smart city… Alors qu’aucun concept spécifique ne se dégageait explicitement de la démarche outre-atlantique, simple et saine réhabilitation d’un secteur économique délaissé stigmatisé par le délabrement de Detroit, l’Allemagne, par le biais ses acteurs économiques concernés, tentait de redonner du souffle à la consommation informatique en faisant parler les objets entre eux. Ce concept très général d’objet que l’on peut décliner sous toutes les formes possibles, du grain de blé à l’usine complète, offre un potentiel sans limites, en volume et en valeur pour l’industrie informatique. La translation de l’Internet vers les Objets (IoT, Internet of Things) donne une saveur grand public et une cohérence toute prête avec les Méga-données (Big Data). Une discrétisation opportune des âges industriels exprimés comme les versions d’un logiciel – normal puisque c’est d’informatique dont il s’agit -  nous amène au quatrième et très ambitieux niveau que les industriels à la traîne doivent impérativement atteindre pour survivre. 
Allemagne, USA, France : la situation du secteur industriel y présente un visage et une dynamique bien différents. L’Allemagne dispose d’une économie florissante, un taux de chômage faible, en appui délibéré sur un pilier industriel entreprenant. Les USA ont connu avec la crise de 2008 l’accélération soudaine d’une désindustrialisation jugée inéluctable. L’industrie américaine s’est pourtant ressaisie et ne cesse de créer des emplois, entraînant toute l’économie derrière elle. En France, les gesticulation politiques restent sans effet : le pays continue de fermer ses usines et d’augmenter son chômage, handicapé par son planisme économique et ses choix géopolitiques. 
Les objectif explicites ou implicites de ces initiatives prises parmi d’autres peuvent se résumer ainsi : 
* stimuler le secteur économique des technologies de l’information (Industrie 4.0) ;
* contribuer au redressement de l’industrie en lui offrant de nouvelles lettres de noblesse (Smart XX)
* convaincre les industriels que la Nation a conscience de l’importance de ce secteur économique (Industrie du Futur).
Comme à son habitude, la France planifie et décide en Hauts Lieux des axes de développement. Il en ressort un inventaire à la Prévert des « solutions » gravées dans la charte Industrie du Futur (Une nouvelle logique, Nouvelles ressources, Ville durable, Mobilité écologique, Transports de demain, Médecine du futur, Économie des données, Objets intelligents, Confiance numérique, Alimentation intelligente.
Quittons le ton ironique pour observer que la réflexion s’élargit au-delà de l’usine et des seules préoccupations digitales (seules trois de ces solutions et trois membres de l’alliance constituée essentiellement de syndicats professionnels sont directement liés à l’informatique). En comparaison, Industrie 4.0 est essentiellement axée sur les « Objets connectés » rassemblant un panel d’équipementiers, d’éditeurs de logiciel et d’universités autour de quelques industriels.  En fait, la prétendue révolution industrielle que nous vivons intervient dans une dimension informationnelle, soit parce que les technologies tangibles sont rendues possibles par les technologies de l’information, soit parce que ces technologies sous-tendent des modes de gestion des entreprises et leurs interactions.
Ces observations sont purement conjoncturelles et opportunistes, portant sur une période riche en initiatives visant à redynamiser l’industrie de l’extérieur. En élargissant la focale d’observation, on se rend compte que ces évolutions ne sont pas en elles-mêmes si rapides ni révolutionnaires. La discontinuité apparaît plutôt de manière singulière lorsqu’une technologie est adoptée en masse par des personnes (le smartphone), des entreprises (l’ERP), un État (le contrôle de vitesse des véhicules par radar) alors qu’elle a été inventée depuis un certain temps. Ce que l’on propose schémamatiquement, c’est un inventaire de technologies en devenir préjugées utiles pour l’industrie et un encouragement à les adopter.
Ces messages et les programmes de recherche associés sont utiles. Mais on peut penser que les industriels n’ont pas attendu ces révélations pour connaître une offre technologique déjà promue par les offreurs, et que les encouragements ne suffisent pas à justifier son adoption ou à faciliter sa mise en œuvre. On notera toutefois les travaux de la Smart Manufacturing Leadership Coalition  qui proposait en 2010 une feuille de route de transformation de l’entreprise , déconseillant toute approche incrémentale. On verra pourquoi ce n’est pas forcément une bonne idée.
Les problèmes des directions informatiques sont bien plus concrets. Les responsables connaissent la technologie et veulent d’abord offrir le meilleur service possible aux utilisateurs, à leur entreprise. Mais ils doivent vivre avec un existant figé dans les fonctions comme dans les mentalités, subir une obsolescence rapide et composer avec des budgets de fonctionnement et d’investissement jugés insuffisants (l’informatique n’est pas l’outil de production) et des contraintes de continuité de service draconiennes. Rappelons, martelons que l’évolution industrielle est aujourd’hui pour l’essentiel de nature informationnelle.
Organisation et contrôle
Système sociotechnique complexe, l'entreprise industrielle interagit au sein d’un environnement social, économique, financier, naturel encore plus complexe. 
Sa nature n’est que partiellement artificielle. Une entreprise n’est pas conçue, planifiée, crée par l’homme ; son existence et son développement résultent d’une vitalité propre née de sa complexité dans laquelle la volonté humaine, celle de ses employés et de ses dirigeants, intervient de manière localisée pour influencer des structures et des comportements qui résultent fondamentalement de ses interactions internes et externes. La naissance même d'une entreprise ne se réduit pas à sa déclaration d'existence légale, simple étape d'un long processus d'émergence, de développement et de disparition. Le créateur comme le dirigeant du moment ne sont que des vecteurs temporaires dont l’influence réelle varie en sens inverse de la taille de l’entreprise.
Organisme vivant, elle le demeure grâce à un métabolisme efficace, une homéostasie bien réglée, des capacités de réparation, régénération, mutation, reproduction effectives (autopoïèse). Consciemment ou non, ses composants – personnes, machines, applications informatiques - interagissent, s’adaptent et tentent de contrôler ceux qui contribuent à assumer leur rôle et à assurer leur existence en son sein et à l’extérieur. Pour éviter que cette complexité ne la désagrège par la loi entropique, l’entreprise s’organise en permanence en sous-ensembles dont les interactions sont régies par la loi de la variété requise [1] : la nécessité pour une entité supérieure d’appréhender toute la variété (nombre d’états possibles) d’une entité qu’il doit contrôler impose la prise en charge (la réduction) de cette complexité au niveau de cette dernière, qui contraint sa variabilité afin de permettre sa commandabilité, et donc assurer son rôle dans un espace d’autonomie approprié. 
Une entreprise comporte un sous-système de production qui concrétise la réalité opérationnelle et l’utilité sociale de l’entreprise. Dans le cas de l’entreprise industrielle, ce sous-système comporte des usines et des machines qui combinent et transforment l’information, la matière et énergie. Cette part physique est particulière dans le sens où les contraintes sont imposées par la physique et l’investissement matériel plutôt que par la psychologie et la spéculation, permettant un comportement plus déterministe, et donc une maîtrise plus assumée de la complexité pour fabriquer un produit homogène, répétable, conforme aux attentes supposées du client. 
Les sciences de l’organisation et du contrôle des procédés physiques sont filles des sciences systémiques et cybernétiques. Tandis que l'organisation s'adresse aux fonctions et interactions immatérielles de l'entreprise, le contrôle des procédés physiques, spécifique à l'entreprise de type industriel s'intéresse aux flux de matières et d'énergie et aux réactions physico-chimiques. Il ne s'agit pas de définitions parfaitement tranchées, ces deux domaines se rencontrent souvent et se confondent parfois, offrant un certain défi à l’analyse des processus et aux applications informatiques.

## Information, informatique et automation
L'information constitue un troisième élément de représentation de l'univers macroscopique avec la matière et l'énergie. Par exemple, une table est constituée de bois, vis et colle (matière), de l'effort outillé du menuisier (énergie), de plans et de savoir-faire (information).  [2].
L'organisation et le contrôle évoqués ci-dessus contribuent à la dimension informationnelle de l'entreprise, de même que ses méthodes, ses brevets, l'état de ses stocks, la connaissance de ses clients, son chiffre d'affaire, sa valorisation en bourse, l'ingénierie de ses usines, la part artistique de ses œuvres d'art…
L'information est une entité polymorphe, parfois très concrète – les pages imprimées d'un livre – souvent diffuse, évanescente (l'harmonie d'une fleur). Elle est subjective dans ses manifestations concrètes (la perception du lecteur, le message XML échangé entre deux applications informatiques) et objective dans sa réalité isolée de toute interaction (le contenu d’un livre fermé dont ni l’écrivain ni le lecteur ne perçoivent la totalité de la connaissance inscrite, le fichier informatique isolé) ref XXX Il n’y a pas à ce jour de consensus sur la définition de la nature physique propre de l'information qui se plaît à utiliser toute sortes de média pour se manifester, se transmettre (rayonnement photonique, expression faciale, papier, écran LEDs, silicium, ondes électromagnétiques, fluides, électricité…). Toutefois, la physique des particules pointe vers la notion élémentaire d'interaction, avatar de l’information, faisant de l'univers une construction fondamentalement, génétiquement informationnelle [2]. De même, les travaux de Ralf Landauer [3] confirmés expérimentalement en ? suggèrent que le traitement non réversible de l’information s’accompagne d’une consommation d’énergie qui ne peut être inférieure à une certaine valeur. En est-il de même quel que soit le support (le cortex cérébral par exemple) ?  L’information, méta concept de la science, se dévoile difficilement à nos esprits qu’elle façonne et anime. 
L’apparition de l’informatique constitue une rupture historique radicale dans les technologies informationnelles. Bien que la définition théorique de la science informatique soit beaucoup plus large (traitement automatique de l'information), l'informatique est généralement assimilée à la technologie électronique sur substrat silicium traitant l'information de manière binaire (l'élément informationnel de base est le bit dont la valeur est 0 ou 1), et aux différentes sciences computationnelles associées. Cette technologie est une simple étape entre les calculateurs analogiques du passé et les calculateurs quantiques qui bourgeonnent depuis les années 1990 et d’autres support computationnel à venir. Le terme « digital » à la mode, utilisé à contrecœur dans le titre de cet ouvrage, répond sans détour à un objectif marketing. Il n’est pas approprié, faisant référence aux « doigts » de la main (le boulier est un calculateur digital), pas plus que le terme « numérique » qui semble restreindre cette technologie au traitement des nombres.
Bien avant la pénétration sociale actuelle, la technologie informatique s’était déjà installé dans tous les rouages de l’entreprise jusqu’au cœur des machines dès les années 1970. 
La contre-réaction mécanique, l’air comprimé et l’électricité ont initialement traité les fonctions computationnelles de contrôle des procédés de fabrication, accompagnant avec succès les débuts de l’automatisation des systèmes industriels. 
Alors que les procédés physiques étaient pilotés par des amplificateurs pneumatiques et des relais électromécaniques, les comptables s’équipaient d’ordinateurs, super calculatrices dotées de mémoire et accouplées à une machine à écrire. Prudente et conservatrice par nature, l’usine attendit que cette technologie fasse ses preuves pour l’adopter progressivement. On peut noter que la technologie informatique accuse aujourd’hui la plus grande longévité dans l’histoire de l’automatique dissociée (celle qui n’est pas partie homogène et intégrée du système contrôlé comme le régulateur de Watt) ref. La technologie électronique analogique n’a par exemple duré que quelques années… 
Cette dissociation est récente et tend à s’accentuer au point que l’on parle de « système informatique ». Après avoir longtemps pourfendu l’utilisation de cette terminologie qui prend acte d’une ingénierie indépendante de celle du système de production dans son ensemble, j’ai dû me rendre à l’évidence à la fois de la réalité de cette situation et de l’imprécision de la notion de système qui s’applique sans difficulté à tout et n’importe quoi. C’est d’ailleurs l’un des objectifs de cet ouvrage que de tenter de briser cette autonomie systémique et de réintroduire le traitement informationnel au cœur du système contrôlé. De nombreux modèles d’architecture ont été explorés, depuis la centralisation totale où un supercaculateur contrôle toute l’usine jusqu’au traitement distribué dans 
L’informatique s'applique à une infinité de cas d’utilisation, que nous ne cessons de découvrir et d’expérimenter.  Au sein de l’entreprise industrielle, la distinction entre les dirigeants, managers et administratifs d'une part, et les opérationnels du plancher de l'usine d'autre part, cols blancs et cols bleus, comptables et ingénieurs, gestion et production, s’est de fait retrouvée dans les applications correspondantes de l’informatique. La technologie informatique appliquée au système opératif appartient au domaine de l’automation et non de l’informatique, prise en charge par des automaticiens, non des informaticiens. Les solutions d’automation ont longtemps écarté les matériels, langages, systèmes d’exploitation et réseaux rapidement banalisés et convergents de l’informatique (PC x86, langage C, Unix, Windows, TCP/IP…) pour adopter des approches spécifiques, propriétaires sensées offrir l’aptitude « temps réel », le déterminisme, la fiabilité et la sécurité exigés par les installations industrielles. C’était d’autant plus vrai que l’on se rapprochait de la machine.
Un second dédoublement schizophrénique s’est créé et maintenu longtemps au sein même du domaine de l’automation, héritage d’une époque où les technologies informationnelles reposaient sur des média spécialisés formant deux disciplines indépendantes de l’ingénierie : Les anciens régleurs chargés de l'instrumentation analogique et du contrôle continu des grandeurs physiques au moyen de l’air comprimé (régulation) ont développé des DCS (Digital Control Systems ou systèmes numériques de contrôle-commande) bien adaptés aux fonctions mathématiques continues (algèbre linéaire, calcul intégral et différentiel). De leur côté les électriciens qui assuraient le contrôle des changements d’état des installations (démarrage-marche-arrêt, droit-milieu-gauche, ouvert-fermé) au moyen de relais électromécaniques ont créé les PLC (pour Programmable Logic Controller ou automates programmables) pour traiter les fonctions discontinues booléennes de séquencement automatique et de résolution combinatoire d’états discrets. Ces derniers dispositifs étaient considérés comme des auxiliaires des machines, l’interface avec l’homme était assurée par des voyants et boutons ou des applications informatiques indépendantes de supervision graphique, là où le DCS proposait une solution intégrée. Si les aptitudes de ces systèmes sont à présent peu différenciées, cette situation perdure sur le marché par-delà les fusions-acquisition comme l'absorption d’Invensys par Schneider, sociétés respectivement actrices des marchés DCS et PLC. Pour simplifier nous parlerons de manière générale de systèmes de contrôle, en charge de l’automatisme des machines et du contrôle du procédé physique qu’ils soient à base de PLC avec supervision ou de DCS.
Côté gestion, les ERPs (Enterprise Resource Planning ou progiciels intégrés de gestion) ont accompli avec succès l’intégration des principales fonctions de l’entreprise en dehors de l’animation des installations physiques (finances, investissements, actifs immobilisés, stocks, personnel, tiers....). Ces fonctions, largement banalisées sur des verticaux industriels bien identifiés et faiblement impliquées dans la création de valeur, pouvaient être imposées par ces applications comme bonnes pratiques mutualisées par l’expérience, mises au service des entreprises pour faciliter l’administration interne et les relations externes. Les ERPs s’intéressent aux systèmes et processus physiques à la maille de détail nécessaire pour pouvoir déterminer les achats, les délais de livraison et l’adéquation des moyens aux prévisions d'activité. Cela fonctionne pour autant que la constante de temps des approvisionnements excède assez largement celle de la fabrication : ce n’est plus toujours le cas, et les méthodes de planification des ressources fixes (charge des machines) et circulantes (matières achetées ou préparées) doivent être repensées (DDMRP). 
Si les ERPs n'ont pas la prétention de contrôler les processus de transformation physiques, ce n'est pas en raison de contraintes techniques, argument qui pouvait être avancé dans le passé, ou d'optimisation architecturale, mais plus simplement pour répondre à la réalité organisationnelle de l'entreprise que nous avons évoqué – cols blancs/cols bleus pour simplifier. Lorsqu'une entreprise industrielle décide de s'équiper d'un nouvel ERP, elle ne lui demandera pas de conduire son système de production, domaine trop complexe dont la connaissance du détail est hors du domaine d'intérêt direct des gestionnaires. Et pourtant, le tissage interactionnel entre les fonctions de gestion de production des ERPs et les fonctions d'exécution de la production ne cesse de se complexifier du fait de la dynamique croissante de la chaîne logistique.  Ceci est en train de changer avec la mode IoT (Internet of Things, Internet des Objets) qui place le client, le fournisseur, l’employé en relation étroite avec le produit à toutes les étapes de son élaboration. La technologie existe depuis longtemps, mais l’opportunité économique s’affirme à travers le succès de l’informatique mobile et la disponibilité des infrastructures d’ubiquité informationnelle (cloud). 

## Naissance du MES
Jusqu’à la fin des années 1980, il n’existait pratiquement aucun lien entre les ERPs  ou les applications qui remplissaient leurs fonctions à l'époque et les systèmes de contrôle. Les technologies étaient d’ailleurs totalement incompatibles : réseaux, systèmes d’exploitation, codage binaire, formats de fichiers… Plusieurs facteurs ont contribué à faire naître un nouveau domaine de support informationnel, aux contours jamais vraiment définis.
Tout a commencé avec l’adoption des standards informatiques dans les systèmes de contrôle. Sous la pression compétitive, les constructeurs de ces systèmes qui fabriquaient les cartes électroniques de leurs calculateurs, développaient leurs systèmes d’exploitation et concevaient toutes les applications ont dû se résoudre à utiliser des composants du (très bon) marché : Une console de conduite et le calculateur associé, équivalent d’un superviseur sous Windows à quelques milliers d'euros d’aujourd’hui avec un écran 19 pouces un clavier durci coûtait l’équivalent de 90 K€ en 1980 hors inflation. Ces montants astronomiques étaient toutefois cohérents avec les prix des technologies mécaniques, pneumatiques et électriques, très lourdes à mettre en œuvre que l’informatique remplaçait déjà avantageusement.
Après L’utilisation marginale de mini calculateurs DEC/PDP ou VAX sous DEC/VMS ou SUN/Solaris (IBM fut peu présent initialement sur ce domaine, alors que l’IBM36 et l'AS400 brillaient dans l'ERP), l’arrivée de PCs sous MS/DOS, puis IBM/OS2 et MS/Windows pour assurer l’interface avec l’opérateur (supervision, conduite) et le traitement des données a réduit considérablement ces prix tout en offrant des aptitudes d’extension applicative et d’interfaçage. Les constructeurs ont résisté plus longtemps au niveau des réseaux (prétexte : Ethernet n’est pas déterministe), des entrées/sorties (le marché informatique n’en produit pas qui soient adaptés au milieu industriel) et des contrôleurs de procédé et PLC (domaine rendu captif par les éléments précédents). Ils sont restés constructeurs à ce niveau, et de plus en plus éditeurs de logiciel pour l’ensemble de la plateforme.
Le second facteur fut le besoin d’édition de rapports. Les fabricants passaient beaucoup de temps à relever des données et à compiler des états pour rendre compte des matières consommées et produites, des temps passés, remplir des fiches de contrôle, etc… Or, beaucoup de ces données étaient acquises dans les systèmes de contrôle devenus potentiellement communicants, il suffisait d’accéder à ces données et de les traiter à l'aide d'outils bureautique. Ce fut le règne des développements sous DBase, puis Access, Excel, Visual Basic alimentés par les données temps réel et historiques des systèmes de contrôle.  
Finalement, il apparut de plus en plus nécessaire d’établir un lien informatique entre les systèmes de gestion ou ERPs et les systèmes de contrôle et ces applications de rapport. Ceci permettait d’éviter des saisies manuelles et de combiner les données de gestion (numéro de lots, ordres de fabrication, attributs qualité) avec les données opérationnelles de la fabrication proprement dite, offrant ainsi la traçabilité, la gestion de la performance, l’ordonnancement fin ainsi que la continuité des processus logistiques, de maintenance et de suivi qualité.  
L’intégration plus étroite entre les processus de gestion et les processus physiques a permis progressivement d’aligner la réalité opérationnelle très spécifique au sein de processus de gestion banalisés de façon à supporter des chaînes logistiques de plus en plus dynamiques et complexes et des exigences du contrôle analytique de gestion. La gestion de production, entre celle des approvisionnements et des livraisons ne se contente plus d’une estimation capacitaire MRP sur une maille de temps large et des nomenclatures aplaties, mais doit connaître l’instant précis où un composant assemblé par un sous-traitant doit être amené au poste de travail, où le transporteur doit enlever le produit sous peine de paralyser la chaîne de fabrication amont, aval, ou les deux. De même l’analyse de l’efficacité et des coûts de production doit prendre en compte des enchaînements parfois complexes des étapes de fabrication et des ressources correspondantes mise en œuvre.
Alors que la mutation informatique n’avait pas eu d’incidence majeure sur les aptitudes de l’automation à assurer le bon déroulement du processus physique, les exigences de respect et de flexibilité de la planification, de traçabilité et de reportage induisent le besoin d'un couplage du domaine opérationnel avec la gestion de production pour prendre en compte les caractéristiques particulières du produit commandé par le client, déterminer le processus physique optimal pour le fabriquer et disposer de l'information contextuelle liée à l'élaboration du produit. 
Tous ces facteurs n’expliquent pas en eux-mêmes l’existence du segment applicatif qui porte le nom de « Manufacturing Execution Systems » ou M.E.S.. D’un côté, les ERP assurent la gestion de la production et se sont adaptés aux exigences des industriels. De l’autre, les systèmes de contrôle des processus physique évoluaient vers des technologies informatiques standard compatibles et potentiellement interopérables avec les précédents. Pourtant, les industriels ne réussissaient pas à obtenir ce qu’ils souhaitaient à l’aide de ces seules solutions. Avec leurs propres ressources, ou l’aide de leurs partenaires intégrateurs, ils devaient développer les applications dont ils avaient réellement besoin. Aujourd’hui encore, ces applications se comptent par dizaines, voire centaines dans les entreprises. En effet, leurs exigences métier spécifiques ne pouvaient être traitées par les ERPs trop éloignés des préoccupations de l'atelier, ni par les systèmes de contrôle trop contraignants par leur orientation temps réel et dépourvus des fonctionnalités de base pour mettre en œuvre simplement de telles applications.
Les intégrateurs sont donc naturellement venus à industrialiser les développements réalisés au cours des projets, capitalisant l’acquisition de ces connaissances et optimisant les futurs projets. Plus ou moins verticalisés ou délibérément conçus comme environnement de développement rapide, de nombreux produits sont apparus sur le marché, au périmètre et à la sémantique très variable, avec pour objectif de fournir un écosystème plus maintenable que les multitudes d’applications spécifiques et indépendantes. 

## Standardisation
L'émergence du marché des progiciels MES fut très progressive. En 1992, face à la timidité du marché, les éditeurs les plus dynamiques se sont regroupés au sein d'un consortium destiné à promouvoir ce segment applicatif dans l'industrie, le MESA (Manufacturing Execution System Association, aujourd'hui Manufacturing Enterprise Solutions Association).
Cet organisme a marqué durablement les esprits par l'établissement en 1997 d'une liste de onze fonctions supposées attendues par les industriels pour supporter leur processus opérationnels, connue sous le nom de "Modèle MESA".
En 1995, l'ISA (Instrumentation Society of America, aujourd'hui the International Society of Automation) lance le projet de standard ANSI/ISA-95 "Enterprise - control system integration" qui sera repris par l'ISO et l'IEC sous le numéro 62264. Ce standard avait pour objectif initial la formalisation des flux de communication entre les systèmes en charge de la gestion de l’entreprise et ceux qui supportent l’exploitation des installations, soit les ERPs d’un côté, les systèmes de contrôle de procédé de l’autre. Rapidement, ce standard s'est heurté à la difficulté d'appréhender le domaine d'intérêt du standard à la jonction entre l'Entreprise et son Système de production. Le titre du standard est révélateur, il pose deux difficultés d'ordre sémantique et organisationnel. D'une part, il oppose l'entreprise, une entité organique au contrôle qui est compris dans le standard comme une fonction associée au système opératif. Pour être cohérent, il aurait fallu le nommer « Enterprise – production system integration ».
D'autre part, il oppose les systèmes d'entreprise et les systèmes de contrôle comme si ces derniers ne faisaient pas partie de l'entreprise. Le titre correct aurait donc dû être « Production planning and control system integration », ou encore « Operations management and Control system integration ».
Aussi, Le modèle MESA, conçu pour des besoins purement marketing étant insuffisant, le troisième opus du standard a tenté de clarifier les éléments fonctionnels à l'intersection des domaines en question. Ce document peu formel, plutôt didactique constitue aujourd'hui la « bible du MES ». Mais le standard ISA-95 est beaucoup plus novateur et intéressant sur les aspects de modélisation qui sous-tendent l'ensemble des structures de données formelles qui en constituent le coeur, à savoir la seconde partie. Ce standard est aujourd'hui la première référence pour l'architecture fonctionnelle et l'interopérabilité de l'informatique industrielle et sera évoqué au chapitre 3.

## Transformation ?
Venons-en à l'objet de cet ouvrage. Le terme "transformation" a pris récemment une connotation marketing à travers un battage médiatique visant à promouvoir le déploiement et le renouvellement de l'informatique en entreprise. J'utilisais depuis longtemps ce terme qui me semblait bien représenter le système 4 du VSM (Viable System Model) de Stafford Beer dont l'objectif est la survie de l'organisme, par son aptitude à percevoir l'environnement et à imaginer de solutions pour s'y adapter. C'est le « système 4 » qui est en charge des activités de modification de l'organisme, de l'entreprise, que ce soit au niveau de ses infrastructures techniques - dont l'informatique fait partie - que du développement des produits, de l'organisation, de la psychologie (y compris son image, sa "Culture"). C'est ce même « système 4 » qui justifie et comprend la veille technologique, l'innovation, le marketing.
Comme tout organisme, l'entreprise industrielle est en évolution permanente pour s'adapter à son environnement, tirer parti des opportunités qui lui sont offertes, mettre en œuvre une stratégie délibérée de ses dirigeants. Tous ses constituants, informatique comprise sont potentiellement impactés par cette évolution, qui n’a pas attendu une quelconque révolution industrielle pour s’exercer sans relâche dans l’entreprise.
Russel Accoff définit 4 types d’adaptation
L'influence de son environnement concerne les marchés, la nature, la société humaine, la législation, la technologie... En interne, les décisions, motivées en premier lieu par l'environnement, sont également affectées par des paramètres subjectifs tels que l'ambition, la créativité ou la sagesse et vont orienter la transformation de l'entreprise de manière plus ou moins progressive ou discontinue.
L'informatique est un des éléments les plus simples à faire évoluer : à coût d’investissements relativement modiques et d’effort humain limité à la pression sur des touches de claviers. L'informatique appliquée aux système industriels ne diffère que peu sur ce point de celle qui gère le domaine non physique à l'exception de la mesure et de l'actionnement. En même temps, l'informatique est un vecteur fondamental de cette transformation dans la mesure où l'entreprise émerge et existe essentiellement au travers des interactions entre ses employés, ses machines, ses clients, ses fournisseurs dont elle constitue le média principal… avec la machine à café !
Cela fait bien des années que j'observe les gesticulations et les frustrations associées à l'évolution informatique. Pour nous limiter à l'informatique industrielle, je citerai pêle-mêle : les grandes difficultés des responsables opérationnels à justifier leurs projets et à obtenir les budgets nécessaires ; la perplexité devant l'éventail fonctionnel présumé du domaine MES et le sentiment d'être attardé sur ce point ; la déception, parfois la révolte des opérateurs en proie à une nouvelle application immature qui bouscule les habitudes, oublie des fonctions, pénalise l'efficacité par rapport aux bonnes vieille solutions jugées obsolètes; les frustrations des intégrateurs et fournisseurs qui ne parviennent pas à établir un dialogue fluide avec l'industriel – le secours d'un consultant en « assistance à maîtrise d'ouvrage » parfois empire la situation ; le dilemme du choix d'une solution dont on perçoit mal l'adéquation à des besoins souvent difficiles à exprimer ; l'absence de réflexion systémique pour cadrer correctement les interactions entre l'atelier et la planification, appauvrissant un projet portant à la base sur l'information (organisation, connaissance…) pour le réduire à une construction technologique…
Les réflexions que je propose, probablement de bon sens, ont toujours été bien accueillies, mais pas toujours suivies d'effet : le naturel reprend vite le dessus. J'espère à travers cet exposé persistant de mes idées aider les responsables de l'informatique industrielle à se détacher de la pression marketing et de la fascination technologique et à positionner leur rôle de manière efficace vis-à-vis de la direction, des opérationnels, des fournisseurs et intégrateurs. Si ce n'est l'inspiration, ils y trouveront peut-être la sérénité d'une démarche claire, la motivation pour transcender leurs collaborateurs et partenaires, les arguments pour échanger de manière constructive avec leur direction et leurs clients internes.
